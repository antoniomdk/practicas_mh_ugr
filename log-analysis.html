<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Antonio Molner Domenech">
  <meta name="author" content="DNI: 77766814L">
  <meta name="author" content="Grupo MH3: Jueves de 17:30h a 19:30h">
  <meta name="author" content="antoniomolner@correo.ugr.es">
  <title>Práctica 2. Aprendizaje de Pesos en Características (APC)</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="reveal.js/css/reveal.css">
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">
  <link rel="stylesheet" href="css/custom.css"/>
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="reveal.js/lib/js/html5shiv.js"></script>
  <![endif]-->
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">Práctica 2. Aprendizaje de Pesos en Características (APC)</h1>
  <p class="author">Antonio Molner Domenech</p>
  <p class="author">DNI: 77766814L</p>
  <p class="author">Grupo MH3: Jueves de 17:30h a 19:30h</p>
  <p class="author">antoniomolner@correo.ugr.es</p>
</section>
<section id="TOC">

</section>

<section id="descripción-del-problema" class="slide level1">
<h1>Descripción del problema</h1>
<p>El problema del Aprendizaje de Pesos en Características (APC) es un problema de búsqueda de codificación real (<span class="math inline"><em>s</em><em>o</em><em>l</em> ∈ ℝ<sup><em>n</em></sup></span>). Consiste en encontrar un vector de pesos que pondere las características asociadas a un modelo. En este caso utilizamos un modelo no paramétrico llamado KNN. La ponderación se realiza multiplicando cada característica por su valor correspondiente dentro del vector de pesos. Es decir, teniendo unos datos de entrada <span class="math inline"><em>X</em> ∈ ℝ<sup><em>m</em> × <em>n</em></sup></span> y un vector de pesos <span class="math inline"><em>w⃗</em> = (<em>w</em><sub>1</sub>, <em>w</em><sub>2</sub>, ..., <em>w</em><sub><em>n</em></sub>)<sup><em>T</em></sup> ∈ ℝ<sup><em>n</em></sup></span>, multiplicamos cada columna por la componente correspondiente para obtener <span class="math inline"><em>X</em>′</span>.</p>
<p>La ponderación se realiza para obtener un balance óptimo entre precisión (o cualquier otra métrica que evalúe el modelo) y sencillez. La sencillez se consigue al eliminar ciertas características cuyo peso está por debajo de un umbral, en nuestro caso, <span class="math inline">0.2</span>, ya que nos aseguramos que no son demasiado relevantes para las predicciones. Un modelo no paramétrico como es el caso de KNN tiene la desventaja de que es costoso hacer predicciones mientras que el tiempo de “fitting” es casi nulo. Por ese motivo es importante mantener únicamente las características relevantes para obtener un modelo eficiente. Además, reducimos el riesgo de sobreajuste ya que obtenemos una función hipótesis más sencilla y menos sensible al ruido.</p>
<p>Para este problema vamos a utilizar dos métodos de validación. El primero, un algoritmo de validación cruzada llamado k-fold, que consiste en dividir el conjunto de entrenamiento en K particiones disjuntas, ajustar el modelo con <span class="math inline"><em>K</em> − 1</span> particiones y validarlo con la partición restante. El proceso se repite con todas las combinaciones posibles (K combinaciones). En nuestro caso usamos <span class="math inline"><em>K</em> = 5</span>, es decir <strong>5-fold cross validation</strong>.</p>
<p>El segundo algoritmo se utiliza para evaluar las soluciones en cada paso de un algoritmo de búsqueda. Lo que se conoce comúnmente como la función fitness o la función objetivo. Para ese caso calculamos la precision con Leave-One-Out que consiste en usar el mismo conjunto de datos tanto para prueba como para validación pero eliminando la muestra en cuestión antes de predecir para evitar una precisión errónea del 100%.</p>
<p>Con esto aclarado, podemos definir el marco de trabajo principal de este proyecto, la función fitness u objetivo y el modelo a utilizar:</p>
<p><br /><span class="math display"><em>f</em>(<em>w⃗</em>) = <em>α</em> × <em>p</em><em>r</em><em>e</em><em>c</em><em>i</em><em>s</em><em>i</em><em>o</em><em>n</em>(<em>w⃗</em>, <em>X</em>) + (1 − <em>α</em>) × <em>r</em><em>e</em><em>d</em><em>u</em><em>c</em><em>c</em><em>i</em><em>o</em><em>n</em>(<em>w⃗</em>)</span><br /></p>
<p>Donde: <br /><span class="math display">$$
reduccion(\vec{w}) = \frac{\text{nº de componentes &lt; umbral}}{\text{nº de componentes total}}$$</span><br /> <br /><span class="math display">$$precision(\vec{w}, X) = \frac{\text{predicciones correctas ponderando con } \vec{w}}{\text{predicciones totales}}$$</span><br /></p>
<p>Para reducir el coste computacional de los algoritmos, vamos a utilizar el clasificador KNN más sencillo usando un solo vecino. Por tanto, para hacer una predicción basta con hallar la clase del vecino más cercano. Se puede utilizar cualquier medida de distancia, en nuestro caso usamos la euclídea <span class="math inline">ℓ<sub>2</sub></span> o <span class="math inline">ℓ<sub>2</sub><sup>2</sup></span>:</p>
<p><br /><span class="math display">$$vecino(\vec{x}) = \underset{\vec{v} \in X}{\operatorname{argmin}} \ distancia(\vec{x}, \vec{v})$$</span><br /></p>
</section>
<section id="descripción-de-la-aplicación-de-los-algoritmos" class="slide level1">
<h1>Descripción de la aplicación de los algoritmos</h1>
<p>Las soluciones a nuestro problema se representan con un vector de pesos <span class="math inline"><em>w⃗</em> = (<em>w</em><sub>1</sub>, <em>w</em><sub>2</sub>, ..., <em>w</em><sub><em>n</em></sub>)<sup><em>T</em></sup> ∈ [0, 1]<sup><em>n</em></sup></span>. Por tanto, tenemos que cada componente <span class="math inline"><em>w</em><sub><em>i</em></sub></span> pondera una característica distinta. Como podemos intuir, características con un peso próximo a 1 son relevantes para el cálculo de la distancia en KNN mientras que las que tienen un peso próximo a 0 son prácticamente irrelevantes.</p>
<p>Matemáticamente, la ponderación de pesos podemos verla como una transformación lineal<br />
<span class="math inline"><em>T</em> : ℝ<sup><em>n</em></sup> → ℝ<sup><em>n</em></sup>, <em>T</em>(<em>x⃗</em>) = (<em>w</em><sub>1</sub><em>x</em><sub><em>i</em></sub>, <em>w</em><sub>2</sub><em>x</em><sub>2</sub>, ..., <em>w</em><sub><em>n</em></sub><em>x</em><sub><em>n</em></sub>)<sup><em>T</em></sup></span>. Claramente podemos ver la matriz asociada a esta aplicación lineal es la siguiente:</p>
<p><br /><span class="math display">$$M_T =
\begin{bmatrix}
    w_1 &amp; 0 &amp; \dots  &amp; 0 \\
    0 &amp; w_{2} &amp; \dots &amp; 0 \\
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
    0 &amp; 0 &amp; \dots  &amp; w_{n}
\end{bmatrix}
$$</span><br /></p>
<p>Esta forma de ver la ponderación es importante a la hora de implementarla, ya que podemos utilizar cualquier biblioteca de cálculo matricial como BLAS o LAPACK para realizar los cálculos de forma eficiente. Incluso más eficiente que multiplicar cada columna de la matriz de datos por su peso correspondiente. Dichas bibliotecas suelen usar instrucciones máquina óptimas y algoritmos paralelos.</p>
<p>Una vez sabemos como transformar los datos, podemos evaluar diferentes algoritmos o soluciones. La forma de evaluar cada algoritmo es siempre la misma:</p>
<ol type="1">
<li>Dividimos el conjunto en 5 particiones disjuntas</li>
<li>Para cada partición:
<ol type="1">
<li>Calculamos los pesos usando el algoritmo en cuestión con las particiones restantes</li>
<li>Transformamos los datos tanto de entrenamiento como de prueba con los pesos obtenidos.</li>
<li>Entrenamos un clasificador KNN con los datos de entrenamiento transformados.</li>
<li>Evaluamos el modelo con el conjunto de prueba transformado (la partición).</li>
</ol></li>
</ol>
<h2 id="knn">KNN</h2>
<p>Nuestro clasificador es bastante sencillo de implementar. El pseudocódigo es el siguiente:</p>
<div class="sourceCode" id="cb1" data-caption="Pseudocódigo del clasificador KNN"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb1-1" title="1"><span class="kw">function</span> KNN(x, X, y)</a>
<a class="sourceLine" id="cb1-2" title="2">  kdtree = build_KDTree(X)</a>
<a class="sourceLine" id="cb1-3" title="3">  nearest_neighbour = KDTree.query(x, k=<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb1-4" title="4">  return y[nearest_neighbour]</a></code></pre></div>
<p>Como se puede observar, se utiliza una árbol KDTree para encontrar el vecino más cercano. Para los conjuntos de datos que estamos utilizando parece una opción sensata comparada con el típico algoritmo de fuerza bruta. La complejidad temporal de estos arboles son de <span class="math inline"><em>O</em>(<em>n</em>)</span> para construirlos y <span class="math inline"><em>O</em>(<em>l</em><em>o</em><em>g</em>(<em>n</em>))</span> hasta <span class="math inline"><em>O</em>(<em>n</em>)</span> en el peor de los casos para consultarlos. Mientras que el algoritmo de fuerza bruta es <span class="math inline"><em>O</em>(<em>n</em>)</span> para cada consulta. Si construimos un solo árbol y realizamos muchas consultas, da un mejor rendimiento que fuerza bruta. <strong>Nota</strong>: Suponemos que el KDTree al hacer una consulta devuelve un vector de índices correspondiente a los k vecinos más cercanos.</p>
<h2 id="evaluacion">Evaluacion</h2>
<p>Para evaluar nuestra solución en las diferentes iteraciones de un algoritmo de búsqueda o una vez entrenado el modelo, se utiliza la siguiente función objetivo:</p>
<p><br /><span class="math display"><em>f</em>(<em>w⃗</em>) = <em>α</em> × <em>p</em><em>r</em><em>e</em><em>c</em><em>i</em><em>s</em><em>i</em><em>o</em><em>n</em>(<em>w⃗</em>, <em>X</em>) + (1 − <em>α</em>) × <em>r</em><em>e</em><em>d</em><em>u</em><em>c</em><em>c</em><em>i</em><em>o</em><em>n</em>(<em>w⃗</em>)</span><br /></p>
<p>Como hemos visto anteriormente, la precisión indicaría que tan bueno es el clasificador KNN de un vecino cuando ponderamos con el vector de pesos <span class="math inline"><em>W⃗</em></span>. La precisión se calcula de dos formas distintas dependiendo de cuando se evalúa.</p>
<p>Si se evalúa con únicamente los datos de entrenamiento, como es el caso para la búsqueda local o los algoritmos genéticos, se utiliza el método Leave-One-Out comentado anteriormente:</p>
<div class="sourceCode" id="cb2" data-caption="Pseudocódigo de la validación Leave-One-Out"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb2-1" title="1"><span class="kw">function</span> accuracy_leave_one_out(X_train, y_train)</a>
<a class="sourceLine" id="cb2-2" title="2">  kdtree = build_KDTree(X)</a>
<a class="sourceLine" id="cb2-3" title="3">  accuracy = <span class="dv">0</span></a>
<a class="sourceLine" id="cb2-4" title="4">  <span class="kw">for</span> x <span class="kw">in</span> rows(X_train):</a>
<a class="sourceLine" id="cb2-5" title="5">    <span class="co">// Cogemos el segundo más cercano porque el primero es él mismo.</span></a>
<a class="sourceLine" id="cb2-6" title="6">    nearest_neighbour = KDTree.query(x, k=<span class="dv">2</span>)[<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb2-7" title="7">    <span class="kw">if</span> y_train[nearest_neighbour] == y_train[x.index] <span class="kw">then</span></a>
<a class="sourceLine" id="cb2-8" title="8">      accuracy = accuracy + <span class="dv">1</span></a>
<a class="sourceLine" id="cb2-9" title="9">  return accuracy / num_rows(X_train)</a></code></pre></div>
<p>Si se evalúa una vez entrenado el modelo con el conjunto de entrenamiento, se utiliza el conjunto de test para calcular la precision.</p>
<div class="sourceCode" id="cb3" data-caption="Pseudocódigo de la validación Hold-out"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb3-1" title="1"><span class="kw">function</span> accuracy_test(X_train, y_train, X_test, y_test)</a>
<a class="sourceLine" id="cb3-2" title="2">  accuracy = <span class="dv">0</span></a>
<a class="sourceLine" id="cb3-3" title="3">  <span class="kw">for</span> x <span class="kw">in</span> rows(X_test):</a>
<a class="sourceLine" id="cb3-4" title="4">    prediction = KNN(x, X_train, y_train)</a>
<a class="sourceLine" id="cb3-5" title="5">    <span class="kw">if</span> prediction == y_test[x.index] <span class="kw">then</span></a>
<a class="sourceLine" id="cb3-6" title="6">      accuracy = accuracy + <span class="dv">1</span></a>
<a class="sourceLine" id="cb3-7" title="7">  return accuracy / num_rows(X_test)</a></code></pre></div>
<p>Como hemos visto anteriormente, cualquier vector de pesos <span class="math inline"><em>w⃗</em> ∈ ℝ<sup><em>d</em></sup></span> no es una solución válida. Cada componente debe estar en el intervalo <span class="math inline">[0, 1]</span> por tanto, es posible que sea necesario capar algunas soluciones. Para ello se puede usar el siguiente algoritmo</p>
<div class="sourceCode" id="cb4" data-caption="Pseudocódigo de la función clip"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb4-1" title="1"><span class="kw">function</span> clip(w)</a>
<a class="sourceLine" id="cb4-2" title="2">  <span class="kw">for</span> w_i <span class="kw">in</span> components(w):</a>
<a class="sourceLine" id="cb4-3" title="3">    <span class="kw">if</span> w_i &lt; <span class="dv">0</span> <span class="kw">then</span>; w_i = <span class="dv">0</span></a>
<a class="sourceLine" id="cb4-4" title="4">    <span class="kw">if</span> w_i &gt; <span class="dv">1</span> <span class="kw">then</span>; w_i = <span class="dv">1</span></a>
<a class="sourceLine" id="cb4-5" title="5">  return w</a></code></pre></div>
</section>
<section id="pseudocódigo-de-los-algoritmos" class="slide level1">
<h1>Pseudocódigo de los algoritmos</h1>
<h2 id="búsqueda-local">Búsqueda Local</h2>
<p>La búsqueda local ya supone un algoritmo más complejo. En nuestro caso utilizamos la búsqueda local del primero mejor, es decir, actualizamos la solución con el primer vecino que tenga un fitness mayor. La generación de cada vecino se realiza mutando una componente aleatoria sin repetición. Esta mutación es simplemente sumar un valor aleatorio de una distribución gaussiana <span class="math inline">𝒩(0, <em>σ</em><sup>2</sup>)</span>. Donde sigma es 0.3 para nuestro caso. El vector de pesos además se inicializa aleatoriamente: <span class="math inline"><em>w⃗</em> = (<em>w</em><sub>0</sub>, <em>w</em><sub>1</sub>, ..., <em>w</em><sub><em>n</em></sub>)<sup><em>T</em></sup></span> donde <span class="math inline"><em>w</em><sub><em>i</em></sub> ∼ 𝒰(0, 1)</span></p>
<p>El algoritmo se detiene cuando generamos 15000 vecinos o cuando no se produce mejora tras generar <span class="math inline">20<em>n</em></span> vecinos, donde <span class="math inline"><em>n</em></span> es el número de características de nuestro conjunto de datos.</p>
<div class="sourceCode" id="cb5" data-caption="Pseudocódigo del algoritmo de Búsqueda Local"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb5-1" title="1"><span class="kw">function</span> local_search(X, y, max_neighbours, sigma, seed):</a>
<a class="sourceLine" id="cb5-2" title="2">    n_features = num_columns(X)</a>
<a class="sourceLine" id="cb5-3" title="3">    feed_random_generator(seed)</a>
<a class="sourceLine" id="cb5-4" title="4">    weights = generate_random_uniform_vector(n_features, <span class="dv">0</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb5-5" title="5">    fitness = evaluate(weights, X, y)</a>
<a class="sourceLine" id="cb5-6" title="6">    n_generated = <span class="dv">0</span></a>
<a class="sourceLine" id="cb5-7" title="7">    last_improvement = <span class="dv">0</span></a>
<a class="sourceLine" id="cb5-8" title="8">    <span class="kw">while</span> n_generated &lt; max_neighbours:</a>
<a class="sourceLine" id="cb5-9" title="9">        w_prime = copy(weights)</a>
<a class="sourceLine" id="cb5-10" title="10">        <span class="kw">for</span> k <span class="kw">in</span> permutation(n_features):</a>
<a class="sourceLine" id="cb5-11" title="11">            n_generated += <span class="dv">1</span></a>
<a class="sourceLine" id="cb5-12" title="12">            last_state = w_prime[k]</a>
<a class="sourceLine" id="cb5-13" title="13">            w_prime[k] += generate_gaussian(<span class="dv">0</span>, sigma)</a>
<a class="sourceLine" id="cb5-14" title="14">            w_prime = clip(w_prime)</a>
<a class="sourceLine" id="cb5-15" title="15">            f = evaluate(w_prime, X, y)</a>
<a class="sourceLine" id="cb5-16" title="16">            <span class="kw">if</span> fitness &lt; f <span class="kw">then</span></a>
<a class="sourceLine" id="cb5-17" title="17">                weights = w_prime</a>
<a class="sourceLine" id="cb5-18" title="18">                fitness = f</a>
<a class="sourceLine" id="cb5-19" title="19">                last_improvement = n_generated</a>
<a class="sourceLine" id="cb5-20" title="20">                <span class="kw">break</span></a>
<a class="sourceLine" id="cb5-21" title="21">            <span class="kw">else</span> <span class="kw">then</span></a>
<a class="sourceLine" id="cb5-22" title="22">              w_prime[k] = last_state</a>
<a class="sourceLine" id="cb5-23" title="23">            diff = n_generated - last_improvement</a>
<a class="sourceLine" id="cb5-24" title="24">            <span class="kw">if</span> n_generated &gt; max_neighbours <span class="kw">or</span> diff &gt; (<span class="dv">20</span> * n_features):</a>
<a class="sourceLine" id="cb5-25" title="25">                return weights</a>
<a class="sourceLine" id="cb5-26" title="26">    return weights</a></code></pre></div>
<p>La función <em>evaluate</em> utilizada en el algoritmo únicamente transforma los datos con los pesos correspondientes y calcula el fitness de la solución.</p>
<div class="sourceCode" id="cb6" data-caption="Pseudocódigo del la función evaluadora de soluciones para Búsqueda Local"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb6-1" title="1"><span class="kw">function</span> evaluate(weights, X, y):</a>
<a class="sourceLine" id="cb6-2" title="2">    <span class="co">// Aplicar la ponderación y eliminar las características</span></a>
<a class="sourceLine" id="cb6-3" title="3">    <span class="co">// con un peso menor a 0.2</span></a>
<a class="sourceLine" id="cb6-4" title="4">    X_transformed = transform(weights, X)</a>
<a class="sourceLine" id="cb6-5" title="5">    accuracy = knn_accuracy_leave_one_out(X_transformed, y)</a>
<a class="sourceLine" id="cb6-6" title="6">    return fitness(weights, accuracy)</a></code></pre></div>
<div class="sourceCode" id="cb7" data-caption="Pseudocódigo del la función fitness"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb7-1" title="1"><span class="kw">function</span> fitness(weights, accuracy, alpha=<span class="dv">0.5</span>, threshold=<span class="dv">0.2</span>):</a>
<a class="sourceLine" id="cb7-2" title="2">    reduction = count(weights &lt; threshold) / length(weights)</a>
<a class="sourceLine" id="cb7-3" title="3">    return alpha * accuracy + (<span class="dv">1</span> - alpha) * reduction</a></code></pre></div>
<h2 id="algoritmos-genéticos">Algoritmos genéticos</h2>
<p>Para el desarrollo de la segunda práctica se ha implementado varios algoritmos evolutivos, entre ellos, algoritmos genéticos. Para el desarrollo de estos algoritmos se han tenido que diseñar diferentes funciones que las podemos clasificar en <em>operadores</em> y en funciones relacionadas con la <em>estrategia evolutiva</em>.</p>
<h3 id="operadores">Operadores</h3>
<h4 id="selección">Selección</h4>
<p>El primer operador implementado es el operador de selección. Para todos los algoritmos evolutivos utilizamos el mismo operador, <strong>torneo binario</strong>. Este operador selecciona los mejores individuos a partir de una serie de torneos aleatorios realizados en parejas de dos individuos. Es decir, se seleccionan dos individuos aleatoriamente y el mejor de los dos se introduce en la nueva población. Este proceso se repite tantas veces como el número de individuos vayamos a seleccionar para la población descendiente.</p>
<div class="sourceCode" id="cb8" data-caption="Pseudocódigo del operador de selección"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb8-1" title="1"><span class="kw">function</span> binaryTournament(individuals, num_selected):</a>
<a class="sourceLine" id="cb8-2" title="2">    chosen = []</a>
<a class="sourceLine" id="cb8-3" title="3">    <span class="kw">for</span> i = <span class="dv">0</span>...num_selected <span class="kw">do</span></a>
<a class="sourceLine" id="cb8-4" title="4">        aspirants = selectRandomly(individuals, <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb8-5" title="5">        <span class="co">// Añade el mejor de los dos seleccionados</span></a>
<a class="sourceLine" id="cb8-6" title="6">        chosen.append(max(aspirants, by=fitness_value)) </a>
<a class="sourceLine" id="cb8-7" title="7">    return chosen</a></code></pre></div>
<h4 id="cruce">Cruce</h4>
<p>Para el operador de cruce hemos implementado dos opciones distintas. El operador BLX-Alpha y el operador Aritmético. Para el caso del primero hemos usado un Alpha de 0.3.</p>
<div class="sourceCode" id="cb9" data-caption="Pseudocódigo de los operadores de cruce"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb9-1" title="1"><span class="kw">function</span> cx_arithmetic(ind1, ind2):</a>
<a class="sourceLine" id="cb9-2" title="2">    alphas = random_vector(len(ind1))</a>
<a class="sourceLine" id="cb9-3" title="3">    c1 = (<span class="dv">1</span> - alphas) * ind1 + alphas * ind2</a>
<a class="sourceLine" id="cb9-4" title="4">    c2 = alphas * ind1 + (<span class="dv">1</span> - alphas) * ind2</a>
<a class="sourceLine" id="cb9-5" title="5">    return c1, c2</a>
<a class="sourceLine" id="cb9-6" title="6"></a>
<a class="sourceLine" id="cb9-7" title="7"></a>
<a class="sourceLine" id="cb9-8" title="8"><span class="kw">function</span> cx_blx(ind1, ind2, alpha):</a>
<a class="sourceLine" id="cb9-9" title="9">    c_max = max(ind1, ind2) <span class="co">// El máximo componente a componente</span></a>
<a class="sourceLine" id="cb9-10" title="10">    c_min = min(ind1, ind2) <span class="co">// El mínimo componente a componente</span></a>
<a class="sourceLine" id="cb9-11" title="11">    inteval = c_max - c_min</a>
<a class="sourceLine" id="cb9-12" title="12">    c1 = uniform_vector(c_min - inteval * alpha,</a>
<a class="sourceLine" id="cb9-13" title="13">                        c_max + inteval * alpha)</a>
<a class="sourceLine" id="cb9-14" title="14">    c2 = uniform_vector(c_min - inteval * alpha,</a>
<a class="sourceLine" id="cb9-15" title="15">                        c_max + inteval * alpha)</a>
<a class="sourceLine" id="cb9-16" title="16">    c1 = clip(c1, <span class="dv">0</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb9-17" title="17">    c2 = clip(c2, <span class="dv">0</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb9-18" title="18">    return c1, c2</a></code></pre></div>
<h4 id="mutación">Mutación</h4>
<p>Para el operador de mutación hemos usado el mismo que para Búsqueda Local, el operador de mutación gaussiano. El cual ha sido modificado para añadir la probabilidad de mutación y para devolver un booleano que indica si se ha realizado la mutación o no. Esto evita recalcular las funciones fitness sobre individuos que no han mutado.</p>
<div class="sourceCode" id="cb10" data-caption="Pseudocódigo del operador de mutación"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb10-1" title="1">def mut_gaussian(individual, mu, sigma, indpb):</a>
<a class="sourceLine" id="cb10-2" title="2">    size = len(individual)</a>
<a class="sourceLine" id="cb10-3" title="3">    mutated = <span class="kw">False</span></a>
<a class="sourceLine" id="cb10-4" title="4">    <span class="kw">for</span> i <span class="kw">in</span> range(size):</a>
<a class="sourceLine" id="cb10-5" title="5">        <span class="kw">if</span> random() &lt; indpb:</a>
<a class="sourceLine" id="cb10-6" title="6">            mutated = <span class="kw">True</span></a>
<a class="sourceLine" id="cb10-7" title="7">            individual[i] += random_gaussian(mu, sigma)</a>
<a class="sourceLine" id="cb10-8" title="8">            <span class="kw">if</span> individual[i] &gt; <span class="dv">1</span>:</a>
<a class="sourceLine" id="cb10-9" title="9">                individual[i] = <span class="dv">1</span></a>
<a class="sourceLine" id="cb10-10" title="10">            elif individual[i] &lt; <span class="dv">0</span>:</a>
<a class="sourceLine" id="cb10-11" title="11">                individual[i] = <span class="dv">0</span></a>
<a class="sourceLine" id="cb10-12" title="12">    return individual, mutated</a></code></pre></div>
<h3 id="estrategias">Estrategias</h3>
<p>En esta sección se encuentra aquellas funciones relacionadas con la estrategia evolutiva de los algoritmos. Existen dos estrategias principales que son, la estrategia generacional y estrategia estacionaria. La primera genera una población del mismo tamaño que la de los padres, y se emplea un reemplazamiento elitista para conservar el mejor de la anterior población. Para la segunda se generan únicamente dos descendientes que compiten con los dos peores de la población actual. Las funciones utilizadas para estas estrategias son las siguientes:</p>
<div class="sourceCode" id="cb11" data-caption="Pseudocódigo de la ejecución de un un algoritmo evolutido "><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb11-1" title="1"><span class="kw">function</span> run(population_size, max_evaluations, cxpb, mupb,</a>
<a class="sourceLine" id="cb11-2" title="2">              generational=<span class="kw">True</span>, mem_strategy=None):</a>
<a class="sourceLine" id="cb11-3" title="3">    hof = HallOfFame(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb11-4" title="4">    pop = create_population(n=population_size)</a>
<a class="sourceLine" id="cb11-5" title="5">    num_generations = <span class="dv">0</span></a>
<a class="sourceLine" id="cb11-6" title="6">    num_evaluations = evaluate_population(pop)</a>
<a class="sourceLine" id="cb11-7" title="7">    hof.update(pop)</a>
<a class="sourceLine" id="cb11-8" title="8">    trace = []</a>
<a class="sourceLine" id="cb11-9" title="9">    step_func = generational_step <span class="kw">if</span> generational <span class="kw">else</span> stationary_step</a>
<a class="sourceLine" id="cb11-10" title="10">    <span class="kw">while</span> num_evaluations &lt; max_evaluations:</a>
<a class="sourceLine" id="cb11-11" title="11">        num_generations += <span class="dv">1</span></a>
<a class="sourceLine" id="cb11-12" title="12">        num_evaluations += step_func(pop, cxpb, mupb,</a>
<a class="sourceLine" id="cb11-13" title="13">                                     mem_strategy, num_generations)</a>
<a class="sourceLine" id="cb11-14" title="14">        hof.update(pop)</a>
<a class="sourceLine" id="cb11-15" title="15">        trace.append(hof[<span class="dv">0</span>].fitness.values[<span class="dv">0</span>])</a>
<a class="sourceLine" id="cb11-16" title="16">    return hof[<span class="dv">0</span>], trace</a></code></pre></div>
<p>Esta es la función que se encarga de ejecutar el algoritmo evolutivo. Es una función genérica que recibe el tamaño de población inicial, número máximo de evaluaciones de la función fitness y las estrategias a emplear. Con esta función se pueden ejecutar tanto algoritmos genéticos (estacionarios y generacionales) como los algoritmos meméticos explicados más adelante.</p>
<p>Como se puede observar, esta función lo único que hace es ejecutar la estrategia evolutiva que corresponda, hasta alcanzar el número máximo de evaluaciones. Mientras, en cada paso se almacena el mejor individuo encontrado hasta el momento, usando un objeto “HallOfFame” que representa una lista ordenada (por fitness) de individuos. Finalmente se devuelve dicho individuo y una traza del valor fitness del mejor individuo de cada generación.</p>
<p>En cada paso del algoritmo anterior se llama a las siguientes funciones:</p>
<div class="sourceCode" id="cb12" data-caption="Pseudocódigo los esquemas de evolución"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb12-1" title="1"><span class="kw">function</span> generational_step(pop, cxpb, mupb, mem_strategy, num_generations):</a>
<a class="sourceLine" id="cb12-2" title="2">    offspring = binaryTournament(pop, len(pop))</a>
<a class="sourceLine" id="cb12-3" title="3">    offspring = crossover_and_mutate(offspring, cxpb, mupb)</a>
<a class="sourceLine" id="cb12-4" title="4">    num_evaluations = evaluate_population(offspring)</a>
<a class="sourceLine" id="cb12-5" title="5">    elitism(pop, offspring)</a>
<a class="sourceLine" id="cb12-6" title="6">    <span class="kw">if</span> mem_strategy <span class="kw">and</span> num_generations % <span class="dv">10</span> == <span class="dv">0</span>:</a>
<a class="sourceLine" id="cb12-7" title="7">        num_evaluations += mem_strategy(population=offspring)</a>
<a class="sourceLine" id="cb12-8" title="8">    pop = offspring</a>
<a class="sourceLine" id="cb12-9" title="9">    return num_evaluations</a>
<a class="sourceLine" id="cb12-10" title="10"></a>
<a class="sourceLine" id="cb12-11" title="11"></a>
<a class="sourceLine" id="cb12-12" title="12"><span class="kw">function</span> stationary_step(pop, cxpb, mupb, mem_strategy, num_generations):</a>
<a class="sourceLine" id="cb12-13" title="13">    offspring = binaryTournament(pop, <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb12-14" title="14">    offspring = crossover_and_mutate(offspring, cxpb, mupb)</a>
<a class="sourceLine" id="cb12-15" title="15">    num_evaluations = evaluate_population(offspring)</a>
<a class="sourceLine" id="cb12-16" title="16">    <span class="kw">if</span> mem_strategy <span class="kw">and</span> num_generations % <span class="dv">10</span> == <span class="dv">0</span>:</a>
<a class="sourceLine" id="cb12-17" title="17">        num_evaluations += mem_strategy(population=offspring)</a>
<a class="sourceLine" id="cb12-18" title="18">    change_worst_ones(pop, offspring)</a>
<a class="sourceLine" id="cb12-19" title="19">    return num_evaluations</a></code></pre></div>
<p>Como vemos, representan los esquemas de evolución comentados al principio de la sección. En cada paso del algoritmo generacional se seleccionan 30 individuos y se aplica elitismo (después del cruce y mutación). Mientras que en el estacionario se seleccionan únicamente dos, y se aplica su reemplazamiento correspondiente.</p>
<p>Estas dos estrategias hacen uso de la función <em>crossover_and_mutate</em> que combina y cruza una lista de individuos en base a sus probabilidades correspondientes. El pseudocódigo de esta función es el siguiente:</p>
<div class="sourceCode" id="cb13" data-caption="Pseudocódigo del cruce y la mutación"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb13-1" title="1"><span class="kw">function</span> crossover_and_mutate(population, cxpb, mutpb):</a>
<a class="sourceLine" id="cb13-2" title="2">    offspring = clone(population)</a>
<a class="sourceLine" id="cb13-3" title="3">    num_crossovers = floor(cxpb * len(offspring))</a>
<a class="sourceLine" id="cb13-4" title="4">    num_mutations = floor(mutpb * len(offspring))</a>
<a class="sourceLine" id="cb13-5" title="5">    <span class="kw">for</span> i = <span class="dv">0</span>..<span class="dv">2</span>..num_crossovers; <span class="kw">do</span></a>
<a class="sourceLine" id="cb13-6" title="6">        offspring[i - <span class="dv">1</span>], offspring[i] = crossover(offspring[i - <span class="dv">1</span>], offspring[i])</a>
<a class="sourceLine" id="cb13-7" title="7">        <span class="co">// Invalida el fitness para calcularlo luego</span></a>
<a class="sourceLine" id="cb13-8" title="8">        delete offspring[i - <span class="dv">1</span>].fitness.values, offspring[i].fitness.values</a>
<a class="sourceLine" id="cb13-9" title="9">    <span class="kw">for</span> i = <span class="dv">0</span>...num_mutations; <span class="kw">do</span></a>
<a class="sourceLine" id="cb13-10" title="10">        offspring[i], mutated = mutate(offspring[i])</a>
<a class="sourceLine" id="cb13-11" title="11">        <span class="kw">if</span> mutated:</a>
<a class="sourceLine" id="cb13-12" title="12">            <span class="co">// Invalida el fitness para calcularlo luego</span></a>
<a class="sourceLine" id="cb13-13" title="13">            delete offspring[i].fitness </a>
<a class="sourceLine" id="cb13-14" title="14">    return offspring</a></code></pre></div>
<p>La última función clave para el desarrollo de estos algoritmos es la de evaluación. La función “evaluate_population” se encarga de evaluar aquellos individuos con un fitness nulo. Estos, son individuos que se han generado nuevos a partir de un cruce y/o mutación. Para evaluar cada individuo se utiliza la misma función fitness que para Búsqueda Local.</p>
<div class="sourceCode" id="cb14" data-caption="Pseudocódigo de la evaluacion de cromosomas"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb14-1" title="1"><span class="kw">function</span> evaluate_population(population):</a>
<a class="sourceLine" id="cb14-2" title="2">    evaluations = <span class="dv">0</span></a>
<a class="sourceLine" id="cb14-3" title="3">    <span class="kw">for</span> ind <span class="kw">in</span> population; <span class="kw">do</span></a>
<a class="sourceLine" id="cb14-4" title="4">        <span class="kw">if</span> ind.fitness <span class="kw">is</span> null; <span class="kw">do</span></a>
<a class="sourceLine" id="cb14-5" title="5">            ind.fitness = evaluate(ind)</a>
<a class="sourceLine" id="cb14-6" title="6">            evaluations += <span class="dv">1</span></a>
<a class="sourceLine" id="cb14-7" title="7">    return evaluations</a></code></pre></div>
<p>function evaluate_population(population): Como vemos, devuelve el numero de evaluaciones de la función fitness. Esto sirve para parar la ejecución del algoritmo cuando se evalúa el fitness un cierto número de veces.</p>
<h3 id="toolbox">Toolbox</h3>
<p>Finalmente, hay un concepto que me gustaría explicar que no aparece en el pseudocódigo pero si en la implementación. La mayoría de estas funciones, reciben un objeto llamado “toolbox”. Este objeto no es más que un contenedor con todos los operadores que se van a utilizar para el algoritmo. Esto hace que la ejecución de un algoritmo evolutivo se pueda abstraer y únicamente haya que crear un “toolbox” con los operadores correspondientes. Esto permite desacoplar el código de operadores y funciones de evaluación, de la lógica de la estrategia evolutiva. Así por ejemplo, cambiar de operador de selección o de cruce, para una misma estrategia (generacional por ej.), es simplemente cambiar un atributo del objeto “toolbox”. Y si queremos cambiar de estrategia basta con indicarle a la función “run” que estrategia queremos.</p>
<h2 id="algoritmos-meméticos">Algoritmos meméticos</h2>
<p>Partiendo de los algoritmos genéticos descritos anteriormente, sabemos que las funciones son genéricas. Si nos fijamos en las estrategias de evolución “generational_step” y “stationary_step”, ambas incluyen un parámetro para la estrategia memética. En caso de que le pasemos la estrategia memética el algoritmo la ejecutará cada 10 generaciones.</p>
<p>Para crear la estrategia memética partimos de la siguiente función:</p>
<pre><code>def memetic_strategy(X, y, max_neighbours, seed, population, num_selected,
                     prob, sort):
    if sort:
        candidates = tools.selBest(population, num_selected)
    else:
        candidates = population[:num_selected]
    evaluations = 0
    for ind in candidates:
        if random() &lt; prob:
            new_ind, trace, n_generated = local_search(X, y, max_neighbours,
                                                       0.3, seed, ind)
            evaluations += n_generated
            ind = new_ind[:]
            ind.fitness = trace[len(trace) - 1]
    return evaluations</code></pre>
<p>Esta función puede ejecutar todas las estrategias meméticas de esta práctica. Por ejemplo, para el algoritmo AM-(1,1.0), usamos prop = 1, num_selected = 10 y sort = False; así con todos los algoritmos meméticos. Para poder utilizar esta función es necesario hacer una aplicación parcial y prefijar los argumentos para las diferentes configuraciones. Esto es posible en el lenguaje de programación que he utilizado para la implementación y por eso he decidido crear una única función “plantilla” de la cual derivar todas las estrategias meméticas.</p>
<p>Como vemos, el desarrollo de estos algoritmos ha sido muy corto debido al uso extensivo de funciones genéricas para los algoritmos anteriores. Lo cuál a permitido introducir las estrategías meméticas sin necesidad de modificar en gran medida el código existente.</p>
</section>
<section id="algoritmo-de-comparación" class="slide level1">
<h1>Algoritmo de comparación</h1>
<h2 id="relief">Relief</h2>
<p>La implementación del algoritmo greedy Relief es bastante sencilla. Para cada muestra en el conjunto de entrenamiento calculamos el amigo (sin contar el mismo) y el enemigo más próximos, y actualizamos el vector de pesos con las distancias de cada uno hacia el punto en cuestión.</p>
<div class="sourceCode" id="cb16" data-caption="Pseudocódigo del algoritmo greedy Relief"><pre class="sourceCode pascal"><code class="sourceCode pascal"><a class="sourceLine" id="cb16-1" title="1"><span class="kw">function</span> relief(X, Y):</a>
<a class="sourceLine" id="cb16-2" title="2">    w = <span class="co">{0, 0,..., 0}</span></a>
<a class="sourceLine" id="cb16-3" title="3">    <span class="kw">for</span> i=<span class="dv">0</span> <span class="kw">to</span> rows_count(X):</a>
<a class="sourceLine" id="cb16-4" title="4">        x, y = X[i], Y[i]</a>
<a class="sourceLine" id="cb16-5" title="5">        X_same_<span class="kw">class</span> = X[Y == y]</a>
<a class="sourceLine" id="cb16-6" title="6">        X_other_<span class="kw">class</span> = X[Y != y]</a>
<a class="sourceLine" id="cb16-7" title="7">        kdtree1 = build_KDTree(X_same_class)</a>
<a class="sourceLine" id="cb16-8" title="8">        kdtree2 = build_KDTree(X_other_class)</a>
<a class="sourceLine" id="cb16-9" title="9">        ally = kdtree1.query(x, k=<span class="dv">2</span>)[<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb16-10" title="10">        enemy = kdtree2.query(x, k=<span class="dv">1</span>)[<span class="dv">0</span>]</a>
<a class="sourceLine" id="cb16-11" title="11">        ally = X_same_class[ally]</a>
<a class="sourceLine" id="cb16-12" title="12">        enemy = X_other_class[enemy]</a>
<a class="sourceLine" id="cb16-13" title="13">        w += abs(x - enemy) - abs(x - ally)</a>
<a class="sourceLine" id="cb16-14" title="14">    w = clip(w)</a>
<a class="sourceLine" id="cb16-15" title="15">    w = w * (<span class="dv">1</span> / max(w))</a>
<a class="sourceLine" id="cb16-16" title="16">    return w</a></code></pre></div>
<p>Como se puede observar, el algoritmo crea dos árboles KDTree en cada iteración lo cuál no es muy eficiente. El forma ideal sería crear un árbol para cada clase antes del bucle y utilizarlos dentro del bucle, pero el algoritmo de por sí ya es bastante eficiente y por legibilidad del código se ha descartado esa opción.</p>
</section>
<section id="proceso-de-desarrollo" class="slide level1">
<h1>Proceso de desarrollo</h1>
<p>Para la implementación de todos los algoritmos, se ha utilizado <strong>Python3</strong>. Las principales fuentes de información utilizadas para el desarrollo han sido el seminario, el guión de prácticas y la documentación oficial de Python y los diferentes paquetes utilizados.</p>
<p>Con el fin de reutilizar todo el código posible, he hecho uso extensivo de la biblioteca de cálculo numérico y manejo de arrays <strong>Numpy</strong>. Esto ha permitido tener una implementación limpia y concisa (~300 lineas totales) con una velocidad de ejecución aceptable en comparación con otros lenguajes como C.</p>
<p>Para la implementación de los algoritmos evolutivos se ha utilizado el framework DEAP, que permite de una forma concisa y eficiente implementar todo tipo de estrategias evolutivas. Se ha usado además para reutilizar algunos operadores como el torneo binario.</p>
<p>También he utilizado algunos <strong>profilers</strong> tanto a nivel de función como a nivel de línea, para detectar los cuellos de botella en el algoritmo de Búsqueda Local y determinar finalmente que partes había que optimizar. Como era de esperar esas partes eran relativas a la función fitness, sobre todo calcular la precisión del clasificador. Por este motivo hice una búsqueda sobre las formas más eficientes de calcular los vecinos y encontré la estructura de datos <strong>KDTree</strong>. El uso de la misma ha permitido tener una implementación más eficiente que usando el típico algoritmo de fuerza bruta.</p>
<p>Además, se realizaron algunas pruebas para optimizar el código compilando parte del mismo usando Cython, Numba y Pythran las cuáles, desgraciadamente, no resultaron exitosas y las mejoras que ofrecían no justificaban la complicación en cuanto a desarrollo y distribución del proyecto.</p>
<p>Finalmente, una vez desarrollado los algoritmos, se envolvieron en una clase con una interfaz similar a los objetos de Scikit-Learn para permitir una integración sencilla con el resto del código. Con estas dos clases, ya se implementó el programa principal.</p>
<p>El programa principal (<em>practica2.py</em>) tiene varias funcionalidades interesantes. La primera de ellas es la <strong>validación en paralelo</strong> de los clasificadores y salida bien formateada de los resultados. El programa una vez obtenidos los resultados genera unos gráficos en formato PNG que se almacenan en la carpeta <strong>output</strong>. Los resultados se pueden también exportar en formato “xslx” de Excel. El programa ofrece una validación de los argumentos recibidos, así como una página de ayuda.</p>
</section>
<section id="manual-de-usuario" class="slide level1">
<h1>Manual de usuario</h1>
<p>Antes de continuar con el manual de usuario me gustaría comentar, que debido al crecimiento del proyecto a lo largo de las sesiones de prácticas, me he tomado la molestia de escribir un página de documentación online. En la que se explica de manera estructurada todos los módulos correspondientes del proyecto, así como su instalación. Puede consultar la documentación en este <a href="https://www.antoniomolner.com/practicas_mh_ugr/">sitio</a>. Aunque le recomiendo visitar la documentación online, en el resto de sección también se explica como instalar y ejecutar el proyecto.</p>
<p>Para poder ejecutar el proyecto es necesario tener instalado <strong>Python3</strong>. El proyecto no está testeado sobre Anaconda aunque posiblemente funcione. Únicamente requiere tener el intérprete y el instalador de paquetes <strong>pip</strong> que suele venir por defecto.</p>
<p>El proyecto tiene una serie de dependencias que son necesarias para poder ejecutarlo. Mi recomendación es utilizar un entorno virtual de Python para instalar las dependencias y así no interferir con los paquetes globales. En el directorio del proyecto <strong>FUENTES</strong>, existe un Makefile que crea el entorno virtual e instala los paquetes localmente. Los paquetes a instalar se encuentra en el fichero “requirements.txt”. La lista es larga pero realmente no se utilizan tantos paquetes explícitamente. Lo que recoge ese archivo son las dependencias y las “dependencias de las dependencias” con sus versiones correspondientes para evitar incompatibilidades.</p>
<p>A efectos prácticos, hay que ejecutar únicamente lo siguiente (dentro del directorio FUENTES):</p>
<div class="sourceCode" id="cb17" data-caption="Ejecución del script para instalar las dependencias"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb17-1" title="1"><span class="fu">make</span> install</a>
<a class="sourceLine" id="cb17-2" title="2"><span class="bu">source</span> ./env/bin/activate</a></code></pre></div>
<blockquote>
<p><strong>Nota:</strong> Si se produce un error al instalar el módulo pykdtree es porque su compilador por defecto no soporta OpenMP. Este error se puede obviar ya que la aplicación usará otro módulo en su lugar.</p>
</blockquote>
<p>Una vez instalado todo, ya se puede utilizar el programa principal. Este programa tiene varios parámetros que se deben especificar: el conjunto de datos, el algoritmo a usar, número de procesos a ejecutar en paralelo, etc. En cualquier momento podemos acceder a la ayuda con <strong>-h</strong>.</p>
<div class="sourceCode" id="cb18" data-caption="Salida de la página de ayuda"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb18-1" title="1"><span class="ex">python3</span> practica2.py -h</a>
<a class="sourceLine" id="cb18-2" title="2"><span class="ex">usage</span>: practica2.py [-h] [--seed SEED] [--n_jobs <span class="dt">{1,2,3,4}</span>] [--trace]</a>
<a class="sourceLine" id="cb18-3" title="3">                    [<span class="ex">--to_excel</span>]</a>
<a class="sourceLine" id="cb18-4" title="4">                    <span class="ex">dataset</span></a>
<a class="sourceLine" id="cb18-5" title="5">                    {<span class="ex">knn</span>,relief,local-search,</a>
<a class="sourceLine" id="cb18-6" title="6">                    <span class="ex">agg-blx</span>,agg-ca,age-blx,age-ca,</a>
<a class="sourceLine" id="cb18-7" title="7">                    <span class="ex">AM-</span>(1,1.0),<span class="ex">AM-</span>(1,0.1),<span class="ex">AM-</span>(1,0.1mej)}</a>
<a class="sourceLine" id="cb18-8" title="8"></a>
<a class="sourceLine" id="cb18-9" title="9"><span class="ex">positional</span> arguments:</a>
<a class="sourceLine" id="cb18-10" title="10">  <span class="ex">dataset</span>               Predefined datasets or a csv file</a>
<a class="sourceLine" id="cb18-11" title="11">  {<span class="ex">knn</span>,relief,local-search,agg-blx,agg-ca,age-blx,age-ca,</a>
<a class="sourceLine" id="cb18-12" title="12">    <span class="ex">AM-</span>(1,1.0),<span class="ex">AM-</span>(1,0.1),<span class="ex">AM-</span>(1,0.1mej)} <span class="ex">Algorithm</span> to use for feature weighting</a>
<a class="sourceLine" id="cb18-13" title="13"></a>
<a class="sourceLine" id="cb18-14" title="14"><span class="ex">optional</span> arguments:</a>
<a class="sourceLine" id="cb18-15" title="15">  <span class="ex">-h</span>, --help            show this help message and exit</a>
<a class="sourceLine" id="cb18-16" title="16">  <span class="ex">--seed</span> SEED           Seed to initialize the random generator (default:</a>
<a class="sourceLine" id="cb18-17" title="17">                        <span class="ex">77766814</span>)</a>
<a class="sourceLine" id="cb18-18" title="18">  <span class="ex">--n_jobs</span> <span class="dt">{1,2,3,4}</span>    Number of jobs to run in parallel to evaluate</a>
<a class="sourceLine" id="cb18-19" title="19">                        <span class="ex">partitions.</span> (default: 1)</a>
<a class="sourceLine" id="cb18-20" title="20">  <span class="ex">--trace</span>               Generate trace for local search (default: False)</a>
<a class="sourceLine" id="cb18-21" title="21">  <span class="ex">--to_excel</span>            Dump results into xlsx file (default: False)</a></code></pre></div>
<p>Así, si queremos ejecutar el algoritmo de AM-(1,1.0) con el conjunto de datos Colposcopy, la semilla 1, y en paralelo, ejecutaríamos lo siguiente:</p>
<pre data-caption="Salida del programa principal"><code>python3 practica2.py colposcopy &#39;AM-(1,1.0)&#39; --seed=1 --n_jobs=4

=======================================================
    COLPOSCOPY     |     AM-(1,1.0)      |  SEED = 1
=======================================================
             Accuracy  Reduction  Aggregation       Time
Partition 1  0.694915   0.951613     0.823264  10.574860
Partition 2  0.666667   0.935484     0.801075  10.933312
Partition 3  0.631579   0.935484     0.783531  11.138601
Partition 4  0.666667   0.935484     0.801075  10.324892
Partition 5  0.719298   0.951613     0.835456   6.054140

         Accuracy  Reduction  Aggregation       Time
Mean     0.675825   0.941935     0.808880   9.805161
Std.Dev  0.033090   0.008834     0.020479   2.120348
Median   0.666667   0.935484     0.801075  10.574860</code></pre>
<blockquote>
<p><strong>NOTA:</strong> La semilla por defecto es 77766814. Es la semilla utilizada para el análisis de resultados.</p>
</blockquote>
<p>El parámetro <em>–trace</em> es muy interesante ya que puesto a True, permite generar un gráfico de como varía la función fitness a lo largo de las iteraciones. Obviamente no es aplicable para Relief. Un ejemplo de gráfico es el siguiente:</p>
<p><img data-src="./img/trace.png" /></p>
<p>Además, la aplicación puede leer cualquier archivo <strong>csv</strong>, en el parámetro dataset únicamente hay que especificar el path del archivo. El único requisito es que la variable a predecir se encuentre en la última columna. Esta variable no hace falta que esté codificada en enteros, puede ser cualquier variable categórica, el sistema se encarga de codificarla.</p>
<p>El Makefile contenido dentro del directorio FUENTES también sirve para ejecutar todos los algoritmos a la vez:</p>
<div class="sourceCode" id="cb20" data-caption="Ejecución de todos los algoritmos"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb20-1" title="1"><span class="fu">make</span> run_all</a></code></pre></div>
<p>GNU Make puede ejecutar varias recetas de forma paralela, pero por defecto lo realiza secuencialmente. Si su procesador es óptimo para el paralelismo, puede ahorrarse tiempo y ejecutar varios algoritmos a la vez:</p>
<div class="sourceCode" id="cb21" data-caption="Ejemplo de paralelización con GNU Make"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb21-1" title="1"><span class="fu">make</span> --jobs=4 run_all</a></code></pre></div>
</section>
<section id="experimentos-y-análisis-de-resultados" class="slide level1">
<h1>Experimentos y Análisis de resultados</h1>
<h2 id="descripción-de-los-casos-del-problema">Descripción de los casos del problema</h2>
<p>Los conjuntos de datos utilizados son los siguientes:</p>
<ol type="1">
<li><p><strong>Colposcopy:</strong> Este conjunto de datos tiene 287 muestras y 62 características reales extraídas de imágenes colposcópicas. El objetivo es clasificar entre positivo y negativo (clasificación binaria).</p></li>
<li><p><strong>Ionosphere</strong>: Este conjunto consta de 352 muestras y 34 características extraídas de datos de radares. Al igual que el conjunto anterior, la variable explicada es categórica binaria.</p></li>
<li><p><strong>Texture</strong>: Diferentes imágenes de texturas se han procesado para extraer 550 muestras y 40 atributos. En este caso la clasificación es entre 11 categorías distintas.</p></li>
</ol>
<h2 id="resultados-obtenidos">Resultados obtenidos</h2>
<p>Para realizar los experimentos se utilizado una semilla específica, mi DNI: 77766814. La semilla se ha utilizado tanto para los algoritmos probabilísticos como para crear las particiones k-fold del conjunto de datos. La funcionalidad de ejecutar la validación en paralelo está implementada y funciona correctamente, pero se ha utilizado un único proceso para evaluar todas las particiones y así, obtener tiempos mínimos de cada algoritmo. Los resultados de la ejecución de los algoritmos son los siguientes:</p>
<p><embed data-src="./img/tables_1.pdf" /></p>
<p><embed data-src="./img/tables_2.pdf" /></p>
<p><embed data-src="./img/tables_3.pdf" /></p>
<h2 id="análisis-de-los-resultados">Análisis de los resultados</h2>
<p>Antes de continuar con el análisis de los resultados es importante mencionar que las muestras recogidas, pese a haberse obtenido en las mismas condiciones (misma semilla), son bastante pequeñas. Se han realizado únicamente 5 particiones por conjunto de datos, lo que nos da una muestra demasiado pequeña que nos impide realizar cualquier test de hipótesis paramétrico. Incluso si realizásemos un test no paramétrico como el test Anderson-Darling, las conclusiones podrían no ser correctas y podríamos cometer errores de Tipo I o Tipo 2 (falsos positivos o falsos negativos).</p>
<p>Por lo explicado anteriormente, cualquier conclusión que saquemos con los datos recogidos pueden no ser extrapolables al resto de situaciones. Aún así, es importante comparar los resultados para entender que algoritmos funcionan mejor sobre nuestros conjuntos de datos específicos y sus particiones correspondientes.</p>
<p>En primer lugar, vemos que el algoritmo 1-NN básico aporta un porcentaje de precisión alto en los casos <em>Ionosphere</em> y <em>Texture</em> y un porcentaje no tan alto en el conjunto <em>Colposcopy</em>. Si bien la métrica de la precisión puede ser válida en <em>Texture</em>, para los otros dos conjuntos puede no funcionar tan bien. Lo ideal sería utilizar alguna otra métrica como AUC, F1-Score, etc. Pero como nuestro objetivo es comparar diferentes algoritmos que utilizan la misma métrica, este detalle no es relevante.</p>
<p>Para el caso <em>Colposcopy</em> vemos que el clasificador básico tiene una precisión muy próxima a las versiones Relief y Búsqueda Local. Incluso una precisión mayor que este último. Para el algoritmo Relief, sorprendentemente, en ese conjunto la reducción es considerable y la precisión se mantiene con respecto a 1-NN, por tanto, podríamos decir que funciona bastante bien para este dataset en concreto. Para el algoritmo de Búsqueda local es importante recalcar una cosa. La diferencia de precision entre 1-NN y este algoritmo, es de tan solo 3%. Es decir, hemos perdido un 3% de precisión usando únicamente el 23% de las características. Esto implica que nuestro algoritmo posiblemente vaya a generalizar mucho mejor que el clasificador 1-NN y el coste computacional de predecir nuevos valores se va a reducir drásticamente. El inconveniente principal de este algoritmo en este conjunto de datos (y en general), es el tiempo de preprocesado. Para obtener los pesos correspondientes tarda de media ~8s, lo cuál es bastante mayor que los otros dos algoritmos comparados aunque no es un tiempo desmesurado.</p>
<p>Lo importante de los algoritmos de APC que estamos implementado es que una vez calculado los pesos óptimos para un conjunto de datos, se validan, y quedan prefijados para el resto del desarrollo. Esto hace que en fases posteriores, realizar predicciones sea mucho más eficiente. Si nos fijamos, se consigue más de un 82% de reducción de media entre los tres conjuntos de datos. Por otra parte, si nuestro objetivo es la inferencia, podemos saber que características tienen más importancia que otras cuando nos enfrentamos a algoritmos de aprendizaje “black-box”, los cuales son difíciles de interpretar, pero con estos métodos podemos desentrañar parte de la información que aprenden. Por estos motivos, los altos tiempos de ejecución del algoritmo BL, los cuáles en realidad no son tan altos comparados con técnicas como hyperparametrización, no deben ser limitantes a la hora de usarlo como parte de un flujo de trabajo en Aprendizaje Automático.</p>
<p>Algo similar pasa con el resto de casos. El algoritmo Relief esta vez si que mejora la precisión con respecto al 1-NN. Ahora si podemos decir que este algoritmo funciona correctamente para estos casos particulares, aunque la reducción es muy baja. Cumple su objetivo que es maximizar el rendimiento del modelo ponderando pero sin reducir las características. Por otra parte, la búsqueda local podríamos decir que es el algoritmo que menor precisión tiene. Esto es debido a que la función fitness pondera por igual la reducción y la precisión por tanto la precisión se me un poco mermada. Aun así, como hemos comentado antes, la diferencia en precisión entre Búsqueda local y el resto de algoritmos no es demasiado grande mientras que la reducción es considerable.</p>
<blockquote>
<p><strong>Nota</strong>: Cuando hablamos de que la diferencia entre precisiones no es demasiado grande, hablamos para estos conjuntos en particular y sin conocimiento previo de la utilización del modelo. En situaciones donde la precisión sea muy importante, como puede ser en evaluaciones médicas, detección de fraude, etc… Si que tendríamos que tener en cuenta estas diferencias. En estos casos, deberíamos ajustar el parámetro <span class="math inline"><em>α</em></span> para ponderar más la precisión, por ejemplo <span class="math inline"><em>α</em> = 0.75</span>.</p>
</blockquote>
<p>Como conclusión final, podríamos decir que usar una buena implementación del algoritmo de búsqueda local que sea escalable para problemas reales con espacios dimensionales más grandes que los aquí utilizados, puede ser una buena estrategia para reducir la dimensionalidad del problema, mejorar la eficiencia en predicciones, interpretar modelos “black-box” o reducir la varianza.</p>
<h2 id="gráficos">Gráficos</h2>
<p>Como parte final del análisis, voy a mostrar varios gráficos explicativos generados tras realizar los experimentos:</p>
<p>Podemos también comparar los algoritmos a partir de los datos recogidos de forma visual:</p>
<figure>
<img data-src="./img/accuracy_colposcopy.png" alt="Accuracy Comparison (Colposcopy)" /><figcaption>Accuracy Comparison (Colposcopy)</figcaption>
</figure>
<figure>
<img data-src="./img/accuracy_ionosphere.png" alt="Accuracy Comparison (Ionosphere)" /><figcaption>Accuracy Comparison (Ionosphere)</figcaption>
</figure>
<figure>
<img data-src="./img/accuracy_texture.png" alt="Accuracy Comparison (Texture)" /><figcaption>Accuracy Comparison (Texture)</figcaption>
</figure>

<h2 id="convergencia">Convergencia</h2>
<p>Uno de los aspectos que yo considero relevante para el análisis de un algoritmo es la convergencia. A continuación se mostrarán unos gráficos de las trazas de los diferentes algoritmos. Para búsqueda local se ha utilizado el valor fitness de la solución, mientras que en los evolutivos, la traza corresponde al fitness del mejor individuo de la población a lo largo de las generaciones.</p>
<figure>
<img data-src="./img/traces1.jpg" alt="Convergencia Algoritmos (1)" /><figcaption>Convergencia Algoritmos (1)</figcaption>
</figure>
<figure>
<img data-src="./img/traces2.jpg" alt="Convergencia Algoritmos (1)" /><figcaption>Convergencia Algoritmos (1)</figcaption>
</figure>
<p>Estos gráficos reflejan la relevancia de las particiones en los conjuntos de datos. Como vemos, el valor de la función fitness aumenta rápidamente en las primeras iteraciones y posteriormente se estabiliza lo que nos da un indicio de que el algoritmo ha convergido o ronda muy próximo a un máximo local. Como vemos en cada partición se llega a un máximo distinto. Esto es debido a que cada partición representa un conjunto de datos totalmente distinto y por tanto la función fitness tiene una geometría distinta. En todas las particiones se utiliza el mismo valor de inicialización, por tanto el punto de inicio es el mismo haciendo que este factor no influya.</p>
<h2 id="análisis-de-tiempos">Análisis de tiempos</h2>
<p>Como podemos observar en los resultados, los algoritmos evolutivos tienen un tiempo de ejecución mucho mayor que los algoritmos anteriores (búsqueda local, relief y 1-NN). Por ese motivo me gustaría analizar en profundidad el motivo de esta diferencia de tiempos.</p>
<p>Tras ejecutar un profiler sobre Búsqueda local, AGE-BLX, AM-(1,1.0) para el conjunto de datos <em>Texture</em>, obtenemos los siguientes resultados:</p>
<figure>
<img data-src="img/pyinstrument_ls_texture.png" alt="Profiling de Búsqueda local" /><figcaption>Profiling de Búsqueda local</figcaption>
</figure>
<figure>
<img data-src="img/pyinstrument_agg_blx.png" alt="Profiling de AGG-BLX" /><figcaption>Profiling de AGG-BLX</figcaption>
</figure>
<figure>
<img data-src="img/pyinstrument_am110.png" alt="Profiling de AM-(1,1.0)" /><figcaption>Profiling de AM-(1,1.0)</figcaption>
</figure>
<p>Como era de esperar, en todos los casos donde se pasa la mayor parte del tiempo es en la función fitness. Para Búsqueda local, el porcentaje es aún mayor, mientras que para los algoritmos evolutivo también hay una parte del tiempo que se emplea en la mutación, cruce y el resto de operadores. Pero realmente, la diferencia principal de tiempos recae en el número de evaluaciones. Para Búsqueda local, el criterio de parada hace que nunca lleguemos a evaluar los 15000 vecinos, mientras que con los algoritmos evolutivos esto siempre pasa. Si los algoritmos evolutivos se ejecutasen con el mismo número de evaluaciones (efectivas) que el algoritmo de búsqueda local, las diferencia de tiempo sería mucho menor.</p>
<p>También decir que como hemos visto antes, hay una parte irreducible del tiempo. Que es el tiempo que dedica el algoritmo a los distintos operadores. Para la implementación que tenemos, los algoritmos evolutivos siempre van a tardar un poco más que la búsqueda local. Pero al reducir el número de evaluaciones, también se reduciría el número de cruces, mutaciones, etc. Por lo que la diferencia de tiempos, como he dicho antes, sería pequeña.</p>
<p>Otro factor también a tener en cuenta, es que los algoritmos evolutivos priorizan la <strong>exploración</strong> sobre la explotación. Si recordamos, nuestra función fitness valora de igual medida la reducción y la precisión. Esto hace que se evalúen constantemente soluciones “peores” donde la reducción es pequeña, comparado con Búsqueda local, por ejemplo. Esto hace que no se reduzcan muchas características al evaluar una solución y se tarde más en calcular la precisión con leave-one-out. Prueba de esto, es la diferencia de tiempos entre los meméticos y los genéticos estacionarios. Ambos evalúan la función fitness el mismo numero de veces. Sin embargo, los meméticos introducen un factor de explotación que hace que rápidamente los individuos de las generaciones tenga una reducción más alta.</p>
<p>Por estos motivos, podemos concluir, para estos conjuntos de datos, que los algoritmos genéticos son los más lentos. Seguidos de los meméticos y de la Búsqueda local. Los algoritmos meméticos son más rápidos que los genéticos porque eliminan parte de ese tiempo irreducible de aplicar mutación, cruce, etc. Y consume más tiempo en la parte de búsqueda local. Por tanto ese tiempo irreducible se disminuye con respecto a los genéticos.</p>
<h3 id="diferencias-entre-algoritmos-evolutivos-y-búsqueda-local">Diferencias entre Algoritmos Evolutivos y Búsqueda Local</h3>
<figure>
<img data-src="img/pyinstrument_agg_ca.png" alt="Profiling de AGG-CA" /><figcaption>Profiling de AGG-CA</figcaption>
</figure>
<h3 id="diferencias-entre-blx-y-cruce-aritmético">Diferencias entre BLX y Cruce Aritmético</h3>
<figure>
<img data-src="img/pyinstrument_agg_ca.png" alt="Profiling de AGG-CA" /><figcaption>Profiling de AGG-CA</figcaption>
</figure>
</section>
<section id="referencias-bibliográficas" class="slide level1">
<h1>Referencias bibliográficas</h1>
<h2 id="entendimiento">Entendimiento</h2>
<p>Al principio, pese a lo básico del algoritmo, no llegaba a comprender como funcionaba realmente Relief. Este paper me fue de gran ayuda:</p>
<p><a href="https://www.academia.edu/2675771/RELIEF_Algorithm_and_Similarity_Learning_for_k-NN">RELIEF Algorithm and Similarity Learning for K-NN</a></p>
<h2 id="implementación">Implementación</h2>
<p>Para la implementación he utilizado la documentación oficial de Python y sus bibliotecas correspondientes:</p>
<ul>
<li><p><a href="https://docs.python.org/3/index.html">Python3 Docs</a></p></li>
<li><p><a href="https://www.scipy.org/">Scipy-Suite</a></p></li>
<li><p><a href="http://scikit-learn.sourceforge.net/stable/index.html">Scikit-Learn</a></p></li>
<li><p><a href="https://joblib.readthedocs.io/en/latest/">joblib (Paralelismo)</a></p></li>
<li><p><a href="https://stackoverflow.com/questions/48126771/nearest-neighbour-search-kdtree">KDTree</a></p></li>
<li><p><a href="https://deap.readthedocs.io/en/master/index.html">Deap</a></p></li>
</ul>
</section>
    </div>
  </div>

  <script src="reveal.js/lib/js/head.min.js"></script>
  <script src="reveal.js/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Push each slide change to the browser history
        history: true,

        // Optional reveal.js plugins
        dependencies: [
          { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
          { src: 'reveal.js/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
